{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import copy\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of the function that allows to load the data in the csv files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_matrix(path, room_size, padding, No_choice):\n",
    "    \"\"\"\n",
    "    Returns two tensors, that contains the inputs and the outputs.\n",
    "    The matrix contains 1 for every available seat, and 0 otherwise. \n",
    "    \n",
    "    path: A string that contains the name of the file\n",
    "    room_size: the size of one side the room (the biggest possible if various size)\n",
    "    padding: the padding needed if various size\n",
    "    No_choice: True if there is the possible to choose no seat\n",
    "    \"\"\"\n",
    "    \n",
    "    # Opening file:\n",
    "    csvfile = open(path, \"r\")\n",
    "    reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    \n",
    "    # Initialization of arrays:\n",
    "    inputs=[]\n",
    "    outputs=[]\n",
    "\n",
    "    #Â Taking the header and the index of useful columns:\n",
    "    header = next(reader) \n",
    "    \n",
    "    ind_ncols = header.index('Cond_NCol')\n",
    "    ind_nrows = header.index('Cond_NRows')\n",
    "    ind_row_available = header.index('RowNumber_Avail')\n",
    "    ind_col_available = header.index('ColNumber_Avail')\n",
    "    ind_chosen = header.index('Chosen')\n",
    "    \n",
    "    \n",
    "    previous, nb_inputs = (-1,-1,-1), 0\n",
    "    for row in reader:\n",
    "        if previous != (int(row[0]),int(row[1]),int(row[2])):\n",
    "            nb_inputs += 1\n",
    "            previous = (int(row[0]),int(row[1]),int(row[2]))\n",
    "            \n",
    "            new_input = [[0 for _ in range(int(row[ind_ncols]))] for _ in range(int(row[ind_nrows]))]\n",
    "            inputs.append(new_input)\n",
    "            \n",
    "            new_output = [[0 for _ in range(int(row[ind_ncols]))] for _ in range(int(row[ind_nrows]))]\n",
    "            outputs.append(new_output)\n",
    "                        \n",
    "        inputs[-1][int(row[ind_row_available])-1][int(row[ind_col_available])-1] = 1\n",
    "        \n",
    "        # Update the output with the chosen place, except if it's on (0,0), which signify no place chosen:\n",
    "        if(int(row[ind_chosen])==1) and int(row[ind_row_available])!= 0:\n",
    "            outputs[-1][int(row[ind_row_available])-1][int(row[ind_col_available])-1] = 1\n",
    "\n",
    "    print(\"Load\", nb_inputs, \"examples as matrices \\n\")\n",
    "    \n",
    "    torch_inputs = []\n",
    "    torch_outputs = []\n",
    "\n",
    "    if padding != 0:\n",
    "        \n",
    "        pad1 = nn.ZeroPad2d((padding,padding,padding,padding))\n",
    "        pad2 = nn.ZeroPad2d((padding,padding,0,0))\n",
    "        pad3 = nn.ZeroPad2d((0,0,padding,padding))\n",
    "        \n",
    "        old_room_size = room_size - 2*padding\n",
    "\n",
    "        for i in range(len(inputs)):\n",
    "            # Applying paddings in function of the room size :\n",
    "            \n",
    "            if len(inputs[i]) == old_room_size:\n",
    "                if len(inputs[i][0]) == old_room_size: # Padding on both directions\n",
    "                    torch_inputs.append(pad1(torch.Tensor(inputs[i])).view(room_size,room_size,1))\n",
    "                    torch_outputs.append(pad1(torch.Tensor(outputs[i])).view(-1))   \n",
    "                    \n",
    "                else: # Padding only on the rows\n",
    "                    torch_inputs.append(pad3(torch.Tensor(inputs[i])).view(room_size,room_size,1))\n",
    "                    torch_outputs.append(pad3(torch.Tensor(outputs[i])).view(-1))     \n",
    "                    \n",
    "            elif len(inputs[i][0]) == old_room_size: # Padding only on the columns\n",
    "                torch_inputs.append(pad2(torch.Tensor(inputs[i])).view(room_size,room_size,1))\n",
    "                torch_outputs.append(pad2(torch.Tensor(outputs[i])).view(-1))     \n",
    "                \n",
    "            else: # No padding\n",
    "                torch_inputs.append(torch.Tensor(inputs[i]).view(room_size,room_size,1))\n",
    "                torch_outputs.append(torch.Tensor(outputs[i]).view(-1))\n",
    "                \n",
    "        torch_inputs, torch_outputs = torch.stack(torch_inputs), torch.stack(torch_outputs)\n",
    "    \n",
    "    else:\n",
    "        torch_inputs = torch.Tensor(inputs).view(nb_inputs,int(room_size),int(room_size),1)\n",
    "        torch_outputs = torch.Tensor(outputs).view(nb_inputs,room_size*room_size)\n",
    "        \n",
    "    if No_choice:\n",
    "        no_choice_output = torch.Tensor([1 if torch.sum(o)== 0 else 0 for o in torch_outputs]).view(-1,1)\n",
    "        torch_outputs = torch.cat((torch_outputs, no_choice_output), dim=1)\n",
    "    \n",
    "    return torch_inputs, torch_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of CNN :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The architecture that we choose to implement is a CNN, with convolutionnal layers and a fully connected layer at the end.\n",
    "We also apply a mask after the linear layer, in order to do a prediction only on the available seats.\n",
    "\n",
    "For the convolutionnal layers, we use 3x3 kernels with padding of 1 to keep the same dimension. \n",
    "The Number of layers and the number of channels (that are the same on each layers) are hyperparameters that can be changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, room_size, nb_channels, nb_conv_layers, No_choice):\n",
    "        \n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.room_size = room_size\n",
    "        self.nb_channels = nb_channels\n",
    "        self.nb_conv_layers = nb_conv_layers\n",
    "        \n",
    "        self.output_size = self.room_size*self.room_size\n",
    "        self.No_choice = No_choice\n",
    "        \n",
    "        if No_choice:\n",
    "            self.output_size = self.room_size*self.room_size+1\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList([nn.Sequential(nn.Conv2d(in_channels=1, out_channels=self.nb_channels, \n",
    "                                                                 kernel_size=3, stride=1, padding=1),\n",
    "                                                       nn.BatchNorm2d(self.nb_channels))])\n",
    "        \n",
    "        if self.nb_conv_layers > 1:\n",
    "            self.conv_layers.extend([nn.Sequential(nn.Conv2d(in_channels=self.nb_channels, out_channels=self.nb_channels, \n",
    "                                                                 kernel_size=3, stride=1, padding=1),\n",
    "                                                   nn.BatchNorm2d(self.nb_channels))\n",
    "                                     for i in range(self.nb_conv_layers-1)])\n",
    "            \n",
    "        self.fc1 = nn.Linear(self.nb_channels*self.room_size*self.room_size, self.output_size)\n",
    "        \n",
    "    def forward(self, input, mask):\n",
    "        x = input.transpose(1,3)\n",
    "        for l in self.conv_layers:\n",
    "            x = l(x)\n",
    "        x = self.fc1(x.view(-1,self.nb_channels*self.room_size*self.room_size))\n",
    "        x = x * mask\n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        predictions = [] \n",
    "        with torch.no_grad():\n",
    "            for inputs in x:\n",
    "                inputs = inputs.to(device)\n",
    "                \n",
    "                masks = inputs.view(-1,self.room_size*self.room_size)\n",
    "                if self.No_choice:\n",
    "                    masks = torch.cat((masks, torch.ones(masks.shape[0],1).to(device)), dim=1)\n",
    "                masks = masks.to(device)\n",
    "                \n",
    "                outputs = self(inputs, masks)\n",
    "                predictions.extend(outputs)\n",
    "        return np.asarray(predictions).reshape(-1)\n",
    "\n",
    "    def evaluate(self, loader):\n",
    "        with torch.no_grad():\n",
    "            correct1, correct5 = 0, 0\n",
    "            for inputs, labels in loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                masks = inputs.view(-1,self.room_size*self.room_size)\n",
    "                if self.No_choice:\n",
    "                    masks = torch.cat((masks, torch.ones(masks.shape[0],1).to(device)), dim=1)\n",
    "                masks = masks.to(device)\n",
    "                \n",
    "                output = self(inputs, masks)\n",
    "                labels = torch.max(labels, 1)[1]\n",
    "                top5 = torch.sort(output, dim = 1, descending = True)[1][:,0:4]\n",
    "                ci1 = 0\n",
    "                ci5 = 0\n",
    "                for i in range(labels.shape[0]):\n",
    "                    if labels[i] == top5[i,0]:\n",
    "                        ci1 += 1\n",
    "                    if labels[i] in top5[i]:\n",
    "                        ci5 += 1\n",
    "                correct1 += ci1/labels.shape[0]\n",
    "                correct5 += ci5/labels.shape[0]\n",
    "            return correct1/len(loader), correct5/len(loader)\n",
    "        \n",
    "    def train(self, train_set, valid_set, \n",
    "              patience = 10, max_it = 10000, verbose = True):\n",
    "        \n",
    "        counter, train_loss, val_loss = 0, None, None\n",
    "        best_val_acc5, best_val_acc1 = -1, -1\n",
    "        history = [-1, -1, -1]\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"{:5s} | {:10s} | {:5s} | {:5s}\".format(\n",
    "                \"epoch\", \"train_loss\", \"top1\", \"top5\"))\n",
    "        for epoch in range(max_it):\n",
    "            running_loss = 0\n",
    "            # early stopping\n",
    "            counter += 1\n",
    "            if counter > patience - 1:\n",
    "                break\n",
    "            for i, data in enumerate(train_set, 1):\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                index_labels = torch.max(labels, 1)[1].to(device)\n",
    "                \n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # forward + backward + optimize\n",
    "                \n",
    "                masks = inputs.view(-1,self.room_size*self.room_size)\n",
    "                if self.No_choice:\n",
    "                    masks = torch.cat((masks, torch.ones(masks.shape[0],1).to(device)), dim=1)\n",
    "                masks = masks.to(device)                \n",
    "                outputs = self.forward(inputs, masks)\n",
    "\n",
    "                train_loss = loss_fn(outputs, index_labels)\n",
    "                running_loss += train_loss.item()\n",
    "                train_loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            val_acc1, val_acc5 = self.evaluate(valid_set)\n",
    "            #train_acc5 = self.evaluate(train_set)[1]\n",
    "            if verbose:\n",
    "                print(\n",
    "                    \"{:5d} | {:10.5f} | {:5.2%} | {:5.2%}\".format(\n",
    "                        epoch, running_loss / len(trainloader_mat),\n",
    "                        val_acc1, val_acc5),\n",
    "                    end=\"\")\n",
    "            if val_acc5 > best_val_acc5:\n",
    "                counter = 0\n",
    "                best_val_acc5 = val_acc5\n",
    "                torch.save(self.state_dict(), \"best_model\")\n",
    "                history[0] = running_loss / len(train_set)\n",
    "                history[1] = val_acc1\n",
    "                history[2] = val_acc5\n",
    "                if verbose:\n",
    "                    print(\"\\tsaved!\", end=\"\")\n",
    "            if verbose:\n",
    "                print(\"\")\n",
    "        self.load_state_dict(torch.load(\"best_model\"))\n",
    "        return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation of a function that allows to treat the case when a pair of seats has to be predicted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_left_seat(inputs,outputs,room_size,No_choice):\n",
    "    update_inputs = copy.deepcopy(inputs.view(-1,room_size,room_size))\n",
    "    \n",
    "    if No_choice:\n",
    "        nc = outputs[:,-1].view(-1,1)\n",
    "        update_outputs = copy.deepcopy(outputs[:,:-1].view(-1,room_size,room_size))\n",
    "    else:\n",
    "        update_outputs = copy.deepcopy(outputs.view(-1,room_size,room_size))\n",
    "        \n",
    "    update_inputs = update_inputs * torch.cat((update_inputs[:,:,1:], torch.zeros(update_inputs.shape[0],room_size,1)),2)\n",
    "    \n",
    "    update_outputs = update_outputs * torch.cat((update_outputs[:,:,1:], torch.zeros(update_outputs.shape[0],room_size,1)),2)\n",
    "\n",
    "    update_inputs = update_inputs.view(-1,room_size,room_size,1)\n",
    "    update_outputs = update_outputs.view(-1,room_size*room_size)\n",
    "    \n",
    "    if No_choice:\n",
    "        update_outputs = torch.cat((update_outputs, nc),1)\n",
    "    \n",
    "    return update_inputs, update_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study of datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informations of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each file, we need its name, and also, the size of the room, the necessary padding, and we also need to know if there's a no-choice option and if it's pairs of seats.\n",
    "\n",
    "To study one file, we just have to choose the corresponding index on the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Studies ALL - ML and ANALYSIS/\"\n",
    "\n",
    "files_train = [\"PS_ConcertData_Study2_FlatFile_INSAMPLE.csv\", \n",
    "               \"PS_Movie_Singles_Study4_CF_24ch_ForcedChoices_INSAMPLE_FlatFileForML.csv\", \n",
    "               \"PS_Movie_Singles_Study4_CF_24ch_withNonChoice_INSAMPLE_FlatFileForML.csv\",\n",
    "               \"PS_Movie_Singles_Study4_NCF_24ch_ForcedChoices_INSAMPLE_FlatFileForML.csv\",\n",
    "               \"PS_Movie_Singles_Study4_NCF_24ch_withNonChoice_INSAMPLE_FlatFileForML.csv\",\n",
    "               \"PS_Concert_Couple_Study3_FC_INSAMPLE_FlatFileForML.csv\", \n",
    "               \"PS_Concert_Couple_Study3_NC_INSAMPLE_FlatFileForML.csv\",\n",
    "               \"PS_Movie_Couple_Study5_FC_3032ch_INSAMPLE_FlatFileForML.csv\",\n",
    "               \"PS_Movie_Couple_Study5_NC_3032ch_INSAMPLE_FlatFileForML.csv\",\n",
    "               \"PS_Movie_Couple_Study5_NC_3032ch_INSAMPLE_75density_FlatFileForML.csv\",\n",
    "              ]\n",
    "\n",
    "files_valid = [\"PS_ConcertData_Study2_FlatFile_HOLDOUT.csv\",\n",
    "               \"PS_Movie_Singles_Study4_CF_24ch_ForcedChoices_HOLDOUT_FlatFileForML.csv\", \n",
    "               \"PS_Movie_Singles_Study4_CF_24ch_withNonChoice_HOLDOUT_FlatFileForML.csv\",\n",
    "               \"PS_Movie_Singles_Study4_NCF_24ch_ForcedChoices_HOLDOUT_FlatFileForML.csv\",\n",
    "               \"PS_Movie_Singles_Study4_NCF_24ch_withNonChoice_HOLDOUT_FlatFileForML.csv\",\n",
    "               \"PS_Concert_Couple_Study3_FC_HOLDOUT_FlatFileForML.csv\", \n",
    "               \"PS_Concert_Couple_Study3_NC_HOLDOUT_FlatFileForML.csv\",\n",
    "               \"PS_Movie_Couple_Study5_FC_3032ch_HOLDOUT_FlatFileForML.csv\",\n",
    "               \"PS_Movie_Couple_Study5_NC_3032ch_HOLDOUT_FlatFileForML.csv\",\n",
    "               \"PS_Movie_Couple_Study5_NC_3032ch_HOLDOUT_75density_FlatFileForML.csv\"\n",
    "              ]\n",
    "\n",
    "room_size_list = [20, 12, 12, 12, 12, 20, 20, 12, 12, 12]\n",
    "\n",
    "padding_list = [5, 0, 0, 0, 0, 4, 4, 0, 0, 0]\n",
    "\n",
    "no_choice_list = [False, False, True, False, True, False, True, False, True, True]\n",
    "\n",
    "couple_list = [False, False, False, False, False, True, True, True, True, True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change here the file to study, and also the hyperparameters of the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSAMPLE :  PS_Movie_Couple_Study5_NC_3032ch_INSAMPLE_75density_FlatFileForML.csv\n",
      "HOLDOUT :  PS_Movie_Couple_Study5_NC_3032ch_HOLDOUT_75density_FlatFileForML.csv\n",
      "ROOM SIZE :  12\n",
      "PADDING :  0\n",
      "NO CHOICE OPTION :  True\n",
      "PAIRS OF SEATS :  True\n"
     ]
    }
   ],
   "source": [
    "# Index of the file to study:\n",
    "ind_file = 9\n",
    "\n",
    "print(\"INSAMPLE : \", files_train[ind_file])\n",
    "print(\"HOLDOUT : \", files_valid[ind_file])\n",
    "print(\"ROOM SIZE : \", room_size_list[ind_file])\n",
    "print(\"PADDING : \", padding_list[ind_file])\n",
    "print(\"NO CHOICE OPTION : \", no_choice_list[ind_file])\n",
    "print(\"PAIRS OF SEATS : \", couple_list[ind_file])\n",
    "\n",
    "\n",
    "# Number of convolutional layers:\n",
    "nb_channels = 1\n",
    "\n",
    "# Number of channels for each convolutional layers:\n",
    "nb_conv_layers = 1\n",
    "\n",
    "# Batch size for the Neural Network:\n",
    "batch_size = 32\n",
    "\n",
    "# Learning rate for ADAM optimizer:\n",
    "lr_opt = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSAMPLE :  PS_Movie_Couple_Study5_NC_3032ch_INSAMPLE_75density_FlatFileForML.csv\n",
      "Load 3004 examples as matrices \n",
      "\n",
      "HOLDOUT :  PS_Movie_Couple_Study5_NC_3032ch_HOLDOUT_75density_FlatFileForML.csv\n",
      "Load 699 examples as matrices \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"INSAMPLE : \", files_train[ind_file])\n",
    "\n",
    "x_train_mat, y_train_mat = load_data_matrix(path = path+files_train[ind_file], \n",
    "                                            room_size = room_size_list[ind_file], \n",
    "                                            padding = padding_list[ind_file],\n",
    "                                            No_choice = no_choice_list[ind_file])\n",
    "\n",
    "print(\"HOLDOUT : \", files_valid[ind_file])\n",
    "x_valid_mat, y_valid_mat = load_data_matrix(path=path+files_valid[ind_file], \n",
    "                                            room_size = room_size_list[ind_file], \n",
    "                                            padding = padding_list[ind_file],\n",
    "                                            No_choice = no_choice_list[ind_file])\n",
    "if couple_list[ind_file]:\n",
    "    x_train_mat, y_train_mat = keep_left_seat(x_train_mat, y_train_mat,\n",
    "                                              room_size = room_size_list[ind_file],\n",
    "                                              No_choice = no_choice_list[ind_file])\n",
    "    x_valid_mat, y_valid_mat = keep_left_seat(x_valid_mat, y_valid_mat,\n",
    "                                              room_size = room_size_list[ind_file],\n",
    "                                              No_choice = no_choice_list[ind_file])\n",
    "\n",
    "train_mat = torch.utils.data.TensorDataset(x_train_mat, y_train_mat)\n",
    "trainloader_mat = torch.utils.data.DataLoader(train_mat, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_mat = torch.utils.data.TensorDataset(x_valid_mat, y_valid_mat)\n",
    "validloader_mat = torch.utils.data.DataLoader(valid_mat, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch | train_loss | top1  | top5 \n",
      "    0 |    4.96272 | 11.33% | 42.33%\tsaved!\n",
      "    1 |    4.91753 | 11.89% | 43.64%\tsaved!\n",
      "    2 |    4.87172 | 12.46% | 44.21%\tsaved!\n",
      "    3 |    4.82420 | 13.06% | 45.77%\tsaved!\n",
      "    4 |    4.77370 | 12.92% | 47.67%\tsaved!\n",
      "    5 |    4.72091 | 13.94% | 48.64%\tsaved!\n",
      "    6 |    4.66422 | 15.07% | 49.49%\tsaved!\n",
      "    7 |    4.60537 | 15.36% | 51.08%\tsaved!\n",
      "    8 |    4.54292 | 16.52% | 51.79%\tsaved!\n",
      "    9 |    4.47745 | 17.23% | 52.76%\tsaved!\n",
      "   10 |    4.40779 | 17.09% | 54.60%\tsaved!\n",
      "   11 |    4.33503 | 17.37% | 55.03%\tsaved!\n",
      "   12 |    4.25802 | 18.22% | 56.33%\tsaved!\n",
      "   13 |    4.17479 | 18.79% | 56.62%\tsaved!\n",
      "   14 |    4.08567 | 19.50% | 57.61%\tsaved!\n",
      "   15 |    3.98881 | 20.24% | 57.67%\tsaved!\n",
      "   16 |    3.88205 | 20.81% | 58.94%\tsaved!\n",
      "   17 |    3.76496 | 20.98% | 60.11%\tsaved!\n",
      "   18 |    3.63875 | 20.55% | 61.55%\tsaved!\n",
      "   19 |    3.50325 | 22.09% | 63.59%\tsaved!\n",
      "   20 |    3.35959 | 22.40% | 65.01%\tsaved!\n",
      "   21 |    3.21267 | 22.82% | 65.18%\tsaved!\n",
      "   22 |    3.06343 | 23.39% | 65.72%\tsaved!\n",
      "   23 |    2.91889 | 23.53% | 66.86%\tsaved!\n",
      "   24 |    2.77884 | 24.13% | 67.00%\tsaved!\n",
      "   25 |    2.65223 | 25.26% | 67.15%\tsaved!\n",
      "   26 |    2.53456 | 25.69% | 68.00%\tsaved!\n",
      "   27 |    2.42838 | 25.69% | 68.42%\tsaved!\n",
      "   28 |    2.33355 | 25.69% | 69.30%\tsaved!\n",
      "   29 |    2.24550 | 25.26% | 69.87%\tsaved!\n",
      "   30 |    2.16603 | 25.12% | 70.30%\tsaved!\n",
      "   31 |    2.09090 | 25.41% | 70.15%\n",
      "   32 |    2.02257 | 25.69% | 70.58%\tsaved!\n",
      "   33 |    1.96020 | 25.69% | 70.58%\n",
      "   34 |    1.90002 | 25.55% | 70.86%\tsaved!\n",
      "   35 |    1.84518 | 26.12% | 70.86%\n",
      "   36 |    1.79202 | 25.69% | 70.58%\n",
      "   37 |    1.74613 | 25.41% | 70.86%\n",
      "   38 |    1.70122 | 25.55% | 70.72%\n",
      "   39 |    1.65950 | 25.12% | 70.86%\n",
      "   40 |    1.62116 | 25.43% | 70.58%\n",
      "   41 |    1.58429 | 25.29% | 70.44%\n",
      "   42 |    1.54935 | 25.15% | 70.44%\n",
      "   43 |    1.51788 | 25.43% | 70.15%\n"
     ]
    }
   ],
   "source": [
    "model = CNN(room_size = room_size_list[ind_file], \n",
    "            nb_channels = nb_channels, \n",
    "            nb_conv_layers = nb_conv_layers,\n",
    "            No_choice = no_choice_list[ind_file])\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr_opt)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "history_cnn = model.train(trainloader_mat, validloader_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 prediction for train set (in %):  0.4178381458966565\n",
      "Top 5 prediction for train set (in %):  0.9244395896656535\n",
      "\n",
      "Top 1 prediction for valid set (in %):  0.25547138047138046\n",
      "Top 5 prediction for valid set (in %):  0.70864898989899\n"
     ]
    }
   ],
   "source": [
    "top1_train, top5_train= model.evaluate(trainloader_mat)\n",
    "top1_valid, top5_valid = model.evaluate(validloader_mat)\n",
    "\n",
    "print(\"Top 1 prediction for train set (in %): \", top1_train)\n",
    "print(\"Top 5 prediction for train set (in %): \", top5_train)\n",
    "\n",
    "print(\"\\nTop 1 prediction for valid set (in %): \", top1_valid)\n",
    "print(\"Top 5 prediction for valid set (in %): \", top5_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
